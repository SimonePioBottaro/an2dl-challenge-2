{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a75bb6ad",
      "metadata": {},
      "source": [
        "# **Soft voting**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900b0225",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enviroment\n",
        "isColab = False\n",
        "colab_dir = \"/gdrive/My Drive/Colab Notebooks/[2025-2026] AN2DL/AN2DL-challenge-2\"\n",
        "\n",
        "isKaggle = False\n",
        "isWsl = True\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4cb00e",
      "metadata": {},
      "source": [
        "## **Loading Enviroment**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e09b8c7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory di default\n",
        "current_dir = os.getcwd()   \n",
        "\n",
        "if isColab:\n",
        "    from google.colab import drive # type: ignore\n",
        "    drive.mount(\"/gdrive\")\n",
        "    current_dir = colab_dir\n",
        "    print(\"In esecuzione su Colab. Google Drive montato.\")\n",
        "    %cd $current_dir\n",
        "elif isKaggle:\n",
        "    kaggle_work_dir = \"/kaggle/working/AN2DL-challenge-2\"\n",
        "    os.makedirs(kaggle_work_dir, exist_ok=True)\n",
        "    current_dir = kaggle_work_dir\n",
        "    print(\"In esecuzione su Kaggle. Directory di lavoro impostata.\")\n",
        "    os.chdir(current_dir)\n",
        "elif isWsl:\n",
        "    local_pref = r\"/mnt/g/Il mio Drive/Colab Notebooks/[2025-2026] AN2DL/AN2DL-challenge-2\"\n",
        "    current_dir = local_pref if os.path.isdir(local_pref) else os.getcwd()\n",
        "    print(f\"Esecuzione su WSL. Directory corrente impostata a: {current_dir}\")\n",
        "    os.chdir(current_dir)\n",
        "else:\n",
        "    print(\"Esecuzione locale. Salto mount Google Drive.\")\n",
        "    local_pref = r\"G:\\Il mio Drive\\Colab Notebooks\\[2025-2026] AN2DL\\AN2DL-challenge-2\"\n",
        "    current_dir = local_pref if os.path.isdir(local_pref) else os.getcwd()\n",
        "    print(f\"Directory corrente impostata a: {current_dir}\")\n",
        "    os.chdir(current_dir)\n",
        "\n",
        "print(f\"Changed directory to: {current_dir}\")\n",
        "\n",
        "# Define absolute paths\n",
        "dataset_dir = os.path.join(current_dir, \"dataset\")\n",
        "train_set_dir = os.path.join(dataset_dir, \"train_data\")\n",
        "test_set_dir = os.path.join(dataset_dir, \"test_data\")\n",
        "label_file = os.path.join(dataset_dir, \"train_labels.csv\")\n",
        "\n",
        "print(f\"Dataset directory: {dataset_dir}\")\n",
        "print(f\"Train set directory: {train_set_dir}\")\n",
        "print(f\"Test set directory: {test_set_dir}\")\n",
        "print(f\"Label file: {label_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e0fdc8",
      "metadata": {},
      "source": [
        "## **Import Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be49326d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be49326d",
        "outputId": "59e423d7-35ea-4fc1-933c-affb303ee9f5"
      },
      "outputs": [],
      "source": [
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "%pip install torchview\n",
        "from torchview import draw_graph\n",
        "\n",
        "\n",
        "# Configurazione di TensorBoard e directory\n",
        "logs_dir = \"tensorboard\"\n",
        "if isColab or isKaggle:\n",
        "    !pkill -f tensorboard \n",
        "    !mkdir -p models\n",
        "    print(\"Killed existing TensorBoard instances and created models directory.\") \n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)  \n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import cv2\n",
        "import copy\n",
        "import shutil\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.gridspec as gridspec\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy import ndimage\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dcbf293",
      "metadata": {},
      "source": [
        "### **Preparing Dataset for colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f17001",
      "metadata": {},
      "outputs": [],
      "source": [
        "if isColab:\n",
        "    drive_dataset_dir = os.path.join(current_dir, \"dataset\")\n",
        "    local_dataset_dir = \"/content/dataset\"\n",
        "\n",
        "    if not os.path.exists(local_dataset_dir):\n",
        "        print(f\"Copying dataset from {drive_dataset_dir} to {local_dataset_dir}...\")\n",
        "        try:\n",
        "            shutil.copytree(drive_dataset_dir, local_dataset_dir)\n",
        "            print(\"Copy complete.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying dataset: {e}\")\n",
        "            print(\"Falling back to Drive dataset (slow).\")\n",
        "            # If copy fails, we stick to the original dataset_dir (which might need cleaning too if it was used directly)\n",
        "            dataset_dir = drive_dataset_dir\n",
        "    else:\n",
        "        print(\"Dataset already copied to local runtime.\")\n",
        "\n",
        "    # If copy succeeded (or already existed), use local path\n",
        "    if os.path.exists(local_dataset_dir):\n",
        "        dataset_dir = local_dataset_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfe95f2",
      "metadata": {},
      "source": [
        "## â³ **Data Loading**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc4301c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loader parameters\n",
        "BATCH_SIZE = 16\n",
        "GRAD_ACCUMULATION_STEPS = 2\n",
        "\n",
        "NORMALIZATION_MEAN = [0.485, 0.456, 0.406]\n",
        "NORMALIZATION_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "IMG_RESIZE = (384, 384)\n",
        "INPUT_SHAPE = (3, *IMG_RESIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e112e14",
      "metadata": {},
      "source": [
        "### **Definitions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d945105",
      "metadata": {},
      "outputs": [],
      "source": [
        "SAMPLES_TO_IGNORE = [\n",
        "    \"img_0001.png\",\n",
        "    \"img_0005.png\",\n",
        "    \"img_0008.png\",\n",
        "    \"img_0012.png\",\n",
        "    \"img_0018.png\",\n",
        "    \"img_0020.png\",\n",
        "    \"img_0022.png\",\n",
        "    \"img_0027.png\",\n",
        "    \"img_0028.png\",\n",
        "    \"img_0036.png\",\n",
        "    \"img_0044.png\",\n",
        "    \"img_0047.png\",\n",
        "    \"img_0048.png\",\n",
        "    \"img_0052.png\",\n",
        "    \"img_0062.png\",\n",
        "    \"img_0078.png\",\n",
        "    \"img_0085.png\",\n",
        "    \"img_0090.png\",\n",
        "    \"img_0094.png\",\n",
        "    \"img_0095.png\",\n",
        "    \"img_0126.png\",\n",
        "    \"img_0129.png\",\n",
        "    \"img_0130.png\",\n",
        "    \"img_0133.png\",\n",
        "    \"img_0136.png\",\n",
        "    \"img_0138.png\",\n",
        "    \"img_0148.png\",\n",
        "    \"img_0150.png\",\n",
        "    \"img_0155.png\",\n",
        "    \"img_0159.png\",\n",
        "    \"img_0161.png\",\n",
        "    \"img_0175.png\",\n",
        "    \"img_0178.png\",\n",
        "    \"img_0179.png\",\n",
        "    \"img_0180.png\",\n",
        "    \"img_0184.png\",\n",
        "    \"img_0187.png\",\n",
        "    \"img_0189.png\",\n",
        "    \"img_0193.png\",\n",
        "    \"img_0196.png\",\n",
        "    \"img_0222.png\",\n",
        "    \"img_0251.png\",\n",
        "    \"img_0254.png\",\n",
        "    \"img_0263.png\",\n",
        "    \"img_0268.png\",\n",
        "    \"img_0286.png\",\n",
        "    \"img_0293.png\",\n",
        "    \"img_0313.png\",\n",
        "    \"img_0319.png\",\n",
        "    \"img_0333.png\",\n",
        "    \"img_0342.png\",\n",
        "    \"img_0344.png\",\n",
        "    \"img_0346.png\",\n",
        "    \"img_0355.png\",\n",
        "    \"img_0368.png\",\n",
        "    \"img_0371.png\",\n",
        "    \"img_0376.png\",\n",
        "    \"img_0380.png\",\n",
        "    \"img_0390.png\",\n",
        "    \"img_0393.png\",\n",
        "    \"img_0407.png\",\n",
        "    \"img_0410.png\",\n",
        "    \"img_0415.png\",\n",
        "    \"img_0424.png\",\n",
        "    \"img_0443.png\",\n",
        "    \"img_0453.png\",\n",
        "    \"img_0459.png\",\n",
        "    \"img_0463.png\",\n",
        "    \"img_0486.png\",\n",
        "    \"img_0497.png\",\n",
        "    \"img_0498.png\",\n",
        "    \"img_0499.png\",\n",
        "    \"img_0509.png\",\n",
        "    \"img_0521.png\",\n",
        "    \"img_0530.png\",\n",
        "    \"img_0531.png\",\n",
        "    \"img_0533.png\",\n",
        "    \"img_0537.png\",\n",
        "    \"img_0540.png\",\n",
        "    \"img_0544.png\",\n",
        "    \"img_0547.png\",\n",
        "    \"img_0557.png\",\n",
        "    \"img_0558.png\",\n",
        "    \"img_0560.png\",\n",
        "    \"img_0565.png\",\n",
        "    \"img_0567.png\",\n",
        "    \"img_0572.png\",\n",
        "    \"img_0578.png\",\n",
        "    \"img_0580.png\",\n",
        "    \"img_0586.png\",\n",
        "    \"img_0602.png\",\n",
        "    \"img_0603.png\",\n",
        "    \"img_0607.png\",\n",
        "    \"img_0609.png\",\n",
        "    \"img_0614.png\",\n",
        "    \"img_0620.png\",\n",
        "    \"img_0623.png\",\n",
        "    \"img_0629.png\",\n",
        "    \"img_0635.png\",\n",
        "    \"img_0639.png\",\n",
        "    \"img_0643.png\",\n",
        "    \"img_0644.png\",\n",
        "    \"img_0645.png\",\n",
        "    \"img_0646.png\",\n",
        "    \"img_0656.png\",\n",
        "    \"img_0657.png\",\n",
        "    \"img_0658.png\",\n",
        "    \"img_0670.png\",\n",
        "    \"img_0673.png\",\n",
        "    \"img_0675.png\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7afdb353",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the full dataframe\n",
        "full_df = pd.read_csv(label_file)\n",
        "\n",
        "# Remove cursed images\n",
        "full_df = full_df[~full_df[\"sample_index\"].isin(SAMPLES_TO_IGNORE)].reset_index(\n",
        "    drop=True\n",
        ")\n",
        "\n",
        "# Label mapping\n",
        "class_names = sorted(full_df[\"label\"].unique())\n",
        "label_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
        "full_df[\"label_index\"] = full_df[\"label\"].map(label_to_index)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e13a32d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_loader(ds, batch_size, shuffle, drop_last=False):\n",
        "    \"\"\"Create a PyTorch DataLoader with optimized settings.\"\"\"\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(6, cpu_cores))\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,\n",
        "        persistent_workers=isWsl,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c536e21",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import ndimage\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.transforms import v2 as transforms\n",
        "\n",
        "\n",
        "class MaskedFixedTileDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A Dataset class that extracts fixed-size patches from the center of tissue masks\n",
        "    to preserve biological scale (magnification), rather than resizing variable crops.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dataframe, img_dir, transforms=None, target_size=(224, 224), debug_max=None\n",
        "    ):\n",
        "        self.samples = []\n",
        "        self.transforms = transforms\n",
        "        self.img_dir = img_dir\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # Handling inference mode (no labels) vs training mode\n",
        "        self.is_inference_mode = False\n",
        "        if dataframe is None or \"label_index\" not in dataframe.columns:\n",
        "            self.is_inference_mode = True\n",
        "            if dataframe is None:\n",
        "                # If just a directory, list images\n",
        "                img_names = sorted(\n",
        "                    [f for f in os.listdir(img_dir) if f.startswith(\"img_\")]\n",
        "                )\n",
        "            else:\n",
        "                img_names = dataframe[\"sample_index\"].tolist()\n",
        "            iterator = zip(img_names, [-1] * len(img_names))\n",
        "            total_items = len(img_names)\n",
        "        else:\n",
        "            iterator = zip(dataframe[\"sample_index\"], dataframe[\"label_index\"])\n",
        "            total_items = len(dataframe)\n",
        "\n",
        "        print(\n",
        "            f\"Processing {total_items} images to extract fixed-size {target_size} tiles...\"\n",
        "        )\n",
        "\n",
        "        count = 0\n",
        "        for img_name, label in tqdm(iterator, total=total_items):\n",
        "            if debug_max and count >= debug_max:\n",
        "                break\n",
        "            self._process_and_extract(img_name, label)\n",
        "            count += 1\n",
        "\n",
        "        print(f\"Extraction complete. Total patches: {len(self.samples)}\")\n",
        "\n",
        "    def _process_and_extract(self, img_name, label):\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        mask_path = os.path.join(self.img_dir, img_name.replace(\"img_\", \"mask_\"))\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            mask = Image.open(mask_path).convert(\"L\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load {img_name}: {e}\")\n",
        "            return\n",
        "\n",
        "        img_w, img_h = image.size\n",
        "        # Create binary mask for component labeling\n",
        "        mask_arr = np.array(mask) > 0\n",
        "\n",
        "        # Label connected components (blobs) in the mask\n",
        "        labeled_mask, n_components = ndimage.label(mask_arr) # type: ignore\n",
        "\n",
        "        for cid in range(1, n_components + 1):\n",
        "            # Extract coordinates of the current blob\n",
        "            ys, xs = np.where(labeled_mask == cid)\n",
        "\n",
        "            # Filter out very small noise artifacts (< 50 pixels)\n",
        "            if len(xs) < 50:\n",
        "                continue\n",
        "\n",
        "            # Calculate the centroid (center of mass) of the blob\n",
        "            cy, cx = int(np.mean(ys)), int(np.mean(xs))\n",
        "\n",
        "            # Define the fixed-size crop window around the centroid\n",
        "            th, tw = self.target_size\n",
        "            half_h, half_w = th // 2, tw // 2\n",
        "\n",
        "            y1 = cy - half_h\n",
        "            y2 = cy + half_h\n",
        "            x1 = cx - half_w\n",
        "            x2 = cx + half_w\n",
        "\n",
        "            # Handle Edge Cases: Calculate intersection with the actual image\n",
        "            img_y1, img_y2 = max(0, y1), min(img_h, y2)\n",
        "            img_x1, img_x2 = max(0, x1), min(img_w, x2)\n",
        "\n",
        "            # Extract the valid region from the image\n",
        "            patch_crop = image.crop((img_x1, img_y1, img_x2, img_y2))\n",
        "\n",
        "            # Calculate required padding if the crop extended beyond image bounds\n",
        "            pad_left = max(0, -x1)\n",
        "            pad_top = max(0, -y1)\n",
        "            pad_right = max(0, x2 - img_w)\n",
        "            pad_bottom = max(0, y2 - img_h)\n",
        "\n",
        "            # If padding is needed, pad with white (255) which is standard background in histology\n",
        "            if pad_left > 0 or pad_top > 0 or pad_right > 0 or pad_bottom > 0:\n",
        "                patch = ImageOps.expand(\n",
        "                    patch_crop,\n",
        "                    border=(pad_left, pad_top, pad_right, pad_bottom),\n",
        "                    fill=255,\n",
        "                )\n",
        "            else:\n",
        "                patch = patch_crop\n",
        "\n",
        "            # Ensure precise size match (e.g., if rounding errors occurred)\n",
        "            if patch.size != self.target_size:\n",
        "                patch = patch.resize(self.target_size, Image.BICUBIC) # type: ignore\n",
        "\n",
        "            # Store in RAM (Efficient for ~2k images yielding ~10k-20k patches)\n",
        "            self.samples.append(\n",
        "                {\"patch\": np.array(patch), \"label\": label, \"parent\": img_name}\n",
        "            )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.samples[idx]\n",
        "        img = Image.fromarray(item[\"patch\"])\n",
        "        label = item[\"label\"]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, label, item[\"parent\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147c9151",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_dataset_stats(dataset_class, dataframe, img_dir):\n",
        "    \"\"\"\n",
        "    Computes channel-wise Mean and Std on the dataset without any normalization applied.\n",
        "    \"\"\"\n",
        "    print(\"Computing dataset Mean and Std (this may take a moment)...\")\n",
        "\n",
        "    # define a simple transform that only converts to tensor\n",
        "    basic_transforms = transforms.Compose(\n",
        "        [transforms.Resize(IMG_RESIZE), transforms.ToTensor()]\n",
        "    )\n",
        "\n",
        "    # Instantiate dataset temporarily\n",
        "    temp_ds = dataset_class(dataframe, img_dir, transforms=basic_transforms)\n",
        "    loader = make_loader(temp_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    nb_samples = 0.0\n",
        "\n",
        "    for data, _, _ in tqdm(loader):\n",
        "        batch_samples = data.size(0)\n",
        "        # Flatten H and W to calculate stats per channel\n",
        "        data = data.view(batch_samples, data.size(1), -1)\n",
        "        mean += data.mean(2).sum(0)\n",
        "        std += data.std(2).sum(0)\n",
        "        nb_samples += batch_samples\n",
        "\n",
        "    mean /= nb_samples\n",
        "    std /= nb_samples\n",
        "\n",
        "    print(f\"\\nDONE. Copy these values into your config:\")\n",
        "    print(f\"NEW_MEAN = {mean.tolist()}\") # type: ignore\n",
        "    print(f\"NEW_STD = {std.tolist()}\") # type: ignore\n",
        "    return mean.tolist(), std.tolist()  # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cadb5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Calculating stats on Training Data...\")\n",
        "    \n",
        "# We use the class we just defined\n",
        "custom_mean, custom_std = compute_dataset_stats(\n",
        "        dataset_class=MaskedFixedTileDataset, \n",
        "        dataframe=full_df, \n",
        "        img_dir=train_set_dir\n",
        "    )\n",
        "\n",
        "NORMALIZATION_MEAN = custom_mean\n",
        "NORMALIZATION_STD = custom_std"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "378879f6",
      "metadata": {},
      "source": [
        "### **Transforms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a69ba8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "\n",
        "train_transform_tl = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(IMG_RESIZE),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=NORMALIZATION_MEAN, std=NORMALIZATION_STD),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_transform_ft = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomResizedCrop(\n",
        "            IMG_RESIZE, scale=(0.8, 1.0), ratio=(0.8, 1.2), antialias=True\n",
        "        ),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=180),  # type: ignore\n",
        "        transforms.RandomApply(\n",
        "            [transforms.ElasticTransform(alpha=50.0, sigma=5.0)], p=0.25\n",
        "        ),\n",
        "        transforms.RandomApply(\n",
        "            [transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0))], p=0.2\n",
        "        ),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "        transforms.RandAugment(num_ops=2, magnitude=8),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=NORMALIZATION_MEAN, std=NORMALIZATION_STD),\n",
        "        transforms.RandomErasing(\n",
        "            p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=\"random\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(IMG_RESIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=NORMALIZATION_MEAN, std=NORMALIZATION_STD),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47996323",
      "metadata": {},
      "source": [
        "#### **Example Visualizations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b14fe3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46b14fe3",
        "outputId": "7b0afa5a-011d-4ff0-d681-6d810b6b87ec"
      },
      "outputs": [],
      "source": [
        "example_dataset = MaskedFixedTileDataset(\n",
        "    dataframe=full_df,\n",
        "    img_dir=train_set_dir,\n",
        "    transforms=data_transforms,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aKwmsAocGJ1y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aKwmsAocGJ1y",
        "outputId": "521ec826-8a67-4ec0-cd4b-f68a91da7c3b"
      },
      "outputs": [],
      "source": [
        "def unnormalize(img, mean, std):\n",
        "    img = np.array(img, copy=True)\n",
        "    for c in range(3):\n",
        "        img[c] = img[c] * std[c] + mean[c]\n",
        "    return np.clip(img, 0, 1)\n",
        "\n",
        "\n",
        "def show_mask_patch_effect(dataset, transforms, n=3):\n",
        "    parents = list({s[\"parent\"] for s in dataset.samples})\n",
        "    parents = random.sample(parents, min(n, len(parents)))\n",
        "\n",
        "    for img_name in parents:\n",
        "        img_path = os.path.join(dataset.img_dir, img_name)\n",
        "        mask_path = os.path.join(dataset.img_dir, img_name.replace(\"img_\", \"mask_\"))\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\")) > 0\n",
        "\n",
        "        labeled_mask, n_components = ndimage.label(mask)  # type: ignore\n",
        "\n",
        "        fig = plt.figure(figsize=(4 * (n_components + 1), 5))\n",
        "        gs = fig.add_gridspec(1, n_components + 1)\n",
        "\n",
        "        # Originale + maschera\n",
        "        ax0 = fig.add_subplot(gs[0])\n",
        "        ax0.imshow(image)\n",
        "        ax0.imshow(mask, alpha=0.4, cmap=\"Reds\")\n",
        "        ax0.set_title(\"Originale + Maschera\")\n",
        "        ax0.axis(\"off\")\n",
        "\n",
        "        col = 1\n",
        "        for cid in range(1, n_components + 1):\n",
        "            ys, xs = np.where(labeled_mask == cid)\n",
        "            if len(xs) < 15:\n",
        "                continue\n",
        "\n",
        "            x1, x2 = xs.min(), xs.max()\n",
        "            y1, y2 = ys.min(), ys.max()\n",
        "\n",
        "            patch = image[y1:y2, x1:x2]\n",
        "            patch_pil = Image.fromarray(patch)\n",
        "\n",
        "            train_img = transforms(patch_pil)\n",
        "            train_img = unnormalize(train_img.numpy(), NORMALIZATION_MEAN, NORMALIZATION_STD)\n",
        "\n",
        "            ax = fig.add_subplot(gs[col])\n",
        "            ax.imshow(np.transpose(train_img, (1, 2, 0)))\n",
        "            ax.set_title(f\"Patch {cid}\")\n",
        "            ax.axis(\"off\")\n",
        "            col += 1\n",
        "\n",
        "        plt.suptitle(f\"{img_name} â€“ Patch estratte dai blob\", fontsize=14)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def5ab26",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_mask_patch_effect(\n",
        "    dataset=example_dataset,\n",
        "    transforms=train_transform_tl,\n",
        "    n=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b044700f",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_mask_patch_effect(\n",
        "    dataset=example_dataset,\n",
        "    transforms=train_transform_ft,\n",
        "    n=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f6b750",
      "metadata": {},
      "source": [
        "## ðŸ§® **Network Parameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c901504",
      "metadata": {},
      "outputs": [],
      "source": [
        "EXPERIMENT_NAME = \"densenet121_384p\"\n",
        "NET_NAME = \"densenet121\"\n",
        "\n",
        "# Training parameters\n",
        "LEARNING_RATE = 1e-4\n",
        "TL_EPOCHS = 100\n",
        "TL_PATIENCE = 5\n",
        "TL_DROPOUT_RATE = 0.45\n",
        "TL_WEIGHT_DECAY = 1e-2\n",
        "\n",
        "# Fine tuning parameters\n",
        "FT_EPOCHS = 200\n",
        "FT_PATIENCE = 12\n",
        "FT_LEARNING_RATE = 1e-5\n",
        "FT_WEIGHT_DECAY = 1e-3\n",
        "FT_DROPOUT_RATE = 0.35\n",
        "N_LAYERS_TO_UNFREEZE = 18\n",
        "MIXUP_ALPHA = 0.2\n",
        "\n",
        "VERBOSE = 5\n",
        "K_FOLD = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd872b8a",
      "metadata": {
        "id": "fd872b8a"
      },
      "source": [
        "## ðŸ§  **Training Functions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea708144",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2, device=\"cuda\"):\n",
        "    \"\"\"Returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"Calculates weighted loss for mixed targets\"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5956abc5",
      "metadata": {
        "id": "5956abc5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, mixup_alpha=0.0, grad_accumulation_steps=1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    for idx, (inputs, targets, _) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if mixup_alpha > 0:\n",
        "            # Generate mixed inputs\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(\n",
        "                inputs, targets, mixup_alpha, device\n",
        "            )\n",
        "\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")): # type: ignore\n",
        "                logits = model(inputs)\n",
        "                # Calculate loss mixing both targets\n",
        "                loss = mixup_criterion(criterion, logits, targets_a, targets_b, lam)\n",
        "        else:\n",
        "            # Standard training\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")): # type: ignore\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss = loss / grad_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # We only update weights every 'accumulation_steps' OR at the very last batch\n",
        "        if (idx + 1) % grad_accumulation_steps == 0 or (idx + 1) == len(train_loader):\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # Reset gradients for the next accumulation cycle\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        running_loss += (loss.item() * grad_accumulation_steps) * inputs.size(0)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        # If mixed, use targets_a for rough accuracy estimation\n",
        "        current_targets = targets_a if mixup_alpha > 0 else targets # type: ignore\n",
        "        all_predictions.append(preds.cpu().numpy())\n",
        "        all_targets.append(current_targets.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(all_targets)\n",
        "    y_pred = np.concatenate(all_predictions)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = accuracy_score(y_true, y_pred)\n",
        "    epoch_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b05dac1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate one epoch with test time augmentation\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): model to validate\n",
        "        val_loader (torch.utils.data.DataLoader): dataset loader\n",
        "        criterion (torch.nn.modules.loss._Loss): criterion\n",
        "        device (torch.device): device\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets, _ in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")): # type: ignore\n",
        "                # TTA Strategy:\n",
        "                # 1. Original\n",
        "                logits_orig = model(inputs)\n",
        "                out1 = F.softmax(logits_orig, dim=1)\n",
        "\n",
        "                # 2. Horizontal Flip\n",
        "                inputs_hf = torch.flip(inputs, dims=[3])\n",
        "                out2 = F.softmax(model(inputs_hf), dim=1)\n",
        "\n",
        "                # 3. Vertical Flip\n",
        "                inputs_vf = torch.flip(inputs, dims=[2])\n",
        "                out3 = F.softmax(model(inputs_vf), dim=1)\n",
        "\n",
        "                # Average predictions\n",
        "                avg_probs = (out1 + out2 + out3) / 3.0\n",
        "\n",
        "            # Calculate Loss OUTSIDE autocast for numerical stability\n",
        "            # Use float32 for loss computation\n",
        "            loss = criterion(logits_orig.float(), targets)\n",
        "                \n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            preds = avg_probs.argmax(dim=1)\n",
        "\n",
        "            all_predictions.append(preds.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(all_targets)\n",
        "    y_pred = np.concatenate(all_predictions)\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_acc = accuracy_score(y_true, y_pred)\n",
        "    epoch_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae97722",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim.swa_utils import AveragedModel, update_bn\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scaler,\n",
        "    device,\n",
        "    scheduler=None,\n",
        "    patience=0,\n",
        "    evaluation_metric=\"val_f1\",\n",
        "    mode=\"max\",\n",
        "    restore_best_weights=True,\n",
        "    writer=None,\n",
        "    verbose=1,\n",
        "    experiment_name=\"\",\n",
        "    mixup_alpha=0.0,\n",
        "    use_swa=False,\n",
        "    swa_start_epoch=10,\n",
        "    grad_accumulation_steps=1,\n",
        ")->tuple[torch.nn.Module, dict]:\n",
        "    \"\"\"\n",
        "    Fit the provided model\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to be trained.\n",
        "        train_loader (torch.utils.data.DataLoader): DataLoader for training data.\n",
        "        val_loader (torch.utils.data.DataLoader): DataLoader for validation data.\n",
        "        epochs (int): Number of training epochs.\n",
        "        criterion (torch.nn.Module): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for training.\n",
        "        scaler (torch.cuda.amp.GradScaler): Gradient scaler for mixed precision training.\n",
        "        device (torch.device): Device to run the training on.\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler or torch.optim.lr_scheduler.ReduceLROnPlateau, optional): Learning rate scheduler. Defaults to None.\n",
        "        patience (int, optional): Number of epochs with no improvement after which training will be stopped. Defaults to 0.\n",
        "        evaluation_metric (str, optional): Metric to evaluate for early stopping and best model selection. Defaults to \"val_f1\".\n",
        "        mode (str, optional): One of {\"min\", \"max\"}. In \"min\" mode, training will stop when the quantity monitored has stopped decreasing; in \"max\" mode it will stop when the quantity monitored has stopped increasing. Defaults to \"max\".\n",
        "        restore_best_weights (bool, optional): Whether to restore model weights from the epoch with the best value of the monitored quantity. Defaults to True.\n",
        "        writer (torch.utils.tensorboard.SummaryWriter, optional): TensorBoard writer for logging. Defaults to None.\n",
        "        verbose (int, optional): Verbosity level. Defaults to 1.\n",
        "        experiment_name (str, optional): Name of the experiment for saving models. Defaults to \"\".\n",
        "        mixup_alpha (float, optional): Alpha value for MixUp data augmentation. Defaults to 0.0.\n",
        "        use_swa (bool, optional): Whether to use Stochastic Weight Averaging (SWA). Defaults to False.\n",
        "        swa_start_epoch (int, optional): Epoch to start averaging for SWA. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.nn.Module, dict]: The trained model and training history.\n",
        "    \"\"\"\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_f1\": [], \"val_loss\": [], \"val_f1\": []}\n",
        "\n",
        "    best_metric = float(\"-inf\") if mode == \"max\" else float(\"inf\")\n",
        "    best_epoch = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Initialize SWA Model if enabled\n",
        "    if use_swa:\n",
        "        print(f\"SWA Enabled. Averaging will start after epoch {swa_start_epoch}.\")\n",
        "        swa_model = AveragedModel(model)\n",
        "    else:\n",
        "        swa_model = None\n",
        "\n",
        "    print(f\"Training {epochs} epochs (MixUp: {mixup_alpha}, SWA: {use_swa})...\")\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss, _, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, mixup_alpha, grad_accumulation_steps)\n",
        "        val_loss, _, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        # 2. Update SWA (if active and past start epoch)\n",
        "        if use_swa and epoch >= swa_start_epoch:\n",
        "            swa_model.update_parameters(model)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            # If using ReduceLROnPlateau, step based on validation metric\n",
        "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                scheduler.step(val_f1)\n",
        "            else:\n",
        "                # If using CosineAnnealing, step based on epoch\n",
        "                scheduler.step()\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "\n",
        "        if writer is not None:\n",
        "            writer.add_scalar(\"Loss/Training\", train_loss, epoch)\n",
        "            writer.add_scalar(\"F1/Training\", train_f1, epoch)\n",
        "            writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
        "            writer.add_scalar(\"F1/Validation\", val_f1, epoch)\n",
        "\n",
        "        if verbose > 0 and (epoch % verbose == 0 or epoch == 1):\n",
        "            print(\n",
        "                f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                f\"Train: Loss={train_loss:.4f}, F1={train_f1:.4f} | \"\n",
        "                f\"Val: Loss={val_loss:.4f}, F1={val_f1:.4f} | \"\n",
        "                f\"LR: {scheduler.get_last_lr()[0] if scheduler is not None else optimizer.param_groups[0]['lr']:.6f}\"\n",
        "            )\n",
        "\n",
        "        current_metric = history[evaluation_metric][-1]\n",
        "        is_improvement = (\n",
        "            (current_metric > best_metric)\n",
        "            if mode == \"max\"\n",
        "            else (current_metric < best_metric)\n",
        "        )\n",
        "\n",
        "        if is_improvement:\n",
        "            best_metric = current_metric\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), \"models/\" + experiment_name + \"_model.pt\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience and patience > 0:\n",
        "                print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                break\n",
        "\n",
        "    # Handle SWA Finalization\n",
        "    if use_swa:\n",
        "        print(\"Finalizing SWA Batch Normalization statistics...\")\n",
        "        # We need to compute BN stats for the averaged weights using the train loader\n",
        "        update_bn(train_loader, swa_model, device=device)\n",
        "\n",
        "        # Save SWA model\n",
        "        torch.save(swa_model.state_dict(), f\"models/{experiment_name}_model.pt\")\n",
        "        print(f\"SWA model saved to models/{experiment_name}_model.pt\")\n",
        "\n",
        "        # Return SWA model as the primary model\n",
        "        return swa_model, history\n",
        "\n",
        "    if restore_best_weights and patience > 0:\n",
        "        model.load_state_dict(torch.load(\"models/\" + experiment_name + \"_model.pt\"))\n",
        "        print(\n",
        "            f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\"\n",
        "        )\n",
        "    elif patience == 0:\n",
        "        torch.save(model.state_dict(), \"models/\" + experiment_name + \"_model.pt\")\n",
        "\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8643d67",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def analyze_performance(model, loader, device, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Generating predictions for Confusion Matrix...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, _ in tqdm(loader, desc=\"Validating\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # --- 1. Confusion Matrix ---\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Normalize by row (True Label) to see recall percentages\n",
        "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        cm_normalized,\n",
        "        annot=True,\n",
        "        fmt=\".2f\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names,\n",
        "    )\n",
        "    plt.ylabel(\"True Label (Ground Truth)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.title(\"Normalized Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- 2. Classification Report ---\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\n",
        "        classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
        "    )\n",
        "\n",
        "    return cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a5ecf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction=\"mean\"):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        # Alpha should be the class weights you already calculated\n",
        "        # If alpha is None, no class weighting is applied\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Clamp inputs to prevent overflow in exp()\n",
        "        inputs = torch.clamp(inputs, min=-100, max=100)\n",
        "        \n",
        "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction=\"none\")\n",
        "        pt = torch.exp(-ce_loss)  # prevents nans when probability is 0\n",
        "        \n",
        "        # Add small epsilon to prevent numerical issues\n",
        "        pt = torch.clamp(pt, min=1e-7, max=1.0)\n",
        "        \n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == \"mean\":\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == \"sum\":\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa79a1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot TL vs FT\n",
        "def plot_history(tl_history, ft_history):\n",
        "    epochs_tl = len(tl_history[\"val_f1\"])\n",
        "    epochs_ft = len(ft_history[\"val_f1\"])\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # F1\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(tl_history[\"train_f1\"], label=\"Train F1 TL\")\n",
        "    plt.plot(tl_history[\"val_f1\"], label=\"Val F1 TL\")\n",
        "    plt.plot(\n",
        "        range(epochs_tl, epochs_tl + epochs_ft),\n",
        "        ft_history[\"train_f1\"],\n",
        "        label=\"Train F1 FT\",\n",
        "    )\n",
        "    plt.plot(\n",
        "        range(epochs_tl, epochs_tl + epochs_ft), ft_history[\"val_f1\"], label=\"Val F1 FT\"\n",
        "    )\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"F1 macro\")\n",
        "    plt.title(\"Andamento F1 TL+FT\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(tl_history[\"train_loss\"], label=\"Train Loss TL\")\n",
        "    plt.plot(tl_history[\"val_loss\"], label=\"Val Loss TL\")\n",
        "    plt.plot(\n",
        "        range(epochs_tl, epochs_tl + epochs_ft),\n",
        "        ft_history[\"train_loss\"],\n",
        "        label=\"Train Loss FT\",\n",
        "    )\n",
        "    plt.plot(\n",
        "        range(epochs_tl, epochs_tl + epochs_ft),\n",
        "        ft_history[\"val_loss\"],\n",
        "        label=\"Val Loss FT\",\n",
        "    )\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Andamento Loss TL+FT\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29d2ad0c",
      "metadata": {
        "id": "29d2ad0c"
      },
      "source": [
        "## ðŸ› ï¸ **Transfer Learning**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f17a8ac",
      "metadata": {
        "id": "3f17a8ac"
      },
      "outputs": [],
      "source": [
        "class EfficientNetCustom(nn.Module):\n",
        "    \"\"\"\n",
        "    Instantiates EfficientNet-B0 with ImageNet weights.\n",
        "    Replaces the classifier head with a high-dropout dense layer to prevent overfitting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, dropout_rate=0.4):\n",
        "        super().__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
        "        self.backbone = torchvision.models.efficientnet_v2_s(weights=self.weights)\n",
        "        \n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(self.dropout_rate),\n",
        "            nn.Linear(in_features, self.num_classes),  # type: ignore\n",
        "        )\n",
        "        self.freeze_backbone()\n",
        "    \n",
        "    def freeze_backbone(self):\n",
        "        # Freeze all layers except the classifier head\n",
        "        for name, param in self.backbone.named_parameters():\n",
        "            if not name.startswith(\"classifier\"):\n",
        "                param.requires_grad = False\n",
        "        # Ensure classifier params are trainable\n",
        "        for param in self.backbone.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def unfreeze_backbone(self, n_layers, all=False):\n",
        "        if all:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = True\n",
        "            return\n",
        "        # Unfreeze the last n_layers of the backbone (excluding classifier which is already trainable)\n",
        "        child_counter = 0\n",
        "        for child in reversed(list(self.backbone.children())):\n",
        "            child_counter += 1\n",
        "            if child_counter <= n_layers:\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c08f15",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DenseNetCustom(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0.4):\n",
        "        super().__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.weights = torchvision.models.DenseNet121_Weights.DEFAULT\n",
        "        self.backbone = torchvision.models.densenet121(weights=self.weights)\n",
        "\n",
        "        # DenseNet classifier is stored in .classifier\n",
        "        in_features = self.backbone.classifier.in_features\n",
        "\n",
        "        # Replace Classifier\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate), \n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "        self.freeze_backbone()\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "        # Freeze all feature layers\n",
        "        for param in self.backbone.features.parameters():\n",
        "            param.requires_grad = False\n",
        "        # Unfreeze classifier\n",
        "        for param in self.backbone.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def unfreeze_backbone(self, n_layers, all=False):\n",
        "        if all:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = True\n",
        "            return\n",
        "\n",
        "        # Keep classifier trainable\n",
        "        for param in self.backbone.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # Get all named parameters in features (in order)\n",
        "        feature_params = list(self.backbone.features.named_parameters())\n",
        "        \n",
        "        if n_layers <= 0:\n",
        "            return\n",
        "        \n",
        "        # Unfreeze the last n_layers parameters\n",
        "        params_to_unfreeze = feature_params[-n_layers:]\n",
        "        \n",
        "        for name, param in params_to_unfreeze:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd6cb3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Wrapper that can interchange between DenseNetCustom and EfficientNetCustom.\n",
        "    Keeps the same constructor signature used in the notebook:\n",
        "    CustomNet(num_classes, dropout_rate, backbone=...)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, dropout_rate=0.4, backbone=\"densenet121\"):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.backbone_name = backbone.lower()\n",
        "\n",
        "        if self.backbone_name in (\"densenet\", \"densenet121\"):\n",
        "            self.backbone = DenseNetCustom(num_classes=num_classes, dropout_rate=dropout_rate)\n",
        "        elif self.backbone_name in (\"efficientnet\", \"efficientnet_v2s\", \"efficientnetv2s\"):\n",
        "            self.backbone = EfficientNetCustom(num_classes=num_classes, dropout_rate=dropout_rate)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone '{backbone}'. Use 'densenet' or 'efficientnet'.\")\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "        # Delegate to underlying implementation\n",
        "        if hasattr(self.backbone, \"freeze_backbone\"):\n",
        "            self.backbone.freeze_backbone()\n",
        "\n",
        "    def unfreeze_backbone(self, n_layers, all=False):\n",
        "        # Delegate to underlying implementation\n",
        "        if hasattr(self.backbone, \"unfreeze_backbone\"):\n",
        "            self.backbone.unfreeze_backbone(n_layers, all=all)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e53e8f77",
      "metadata": {},
      "source": [
        "## **K Fold Routine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f93d7e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import gc\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "def run_k_fold_training(full_df, n_splits=5, base_experiment_name=\"efficientnet_v2s\", writer=None):\n",
        "    \"\"\"\n",
        "    Orchestrates the complete K-Fold Cross Validation pipeline.\n",
        "    For each fold:\n",
        "      1. Splits data\n",
        "      2. Runs Transfer Learning (TL) -> Warmup\n",
        "      3. Runs Fine Tuning (FT) -> Optimization with MixUp & SWA\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize K-Fold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "\n",
        "    # Store results\n",
        "    fold_results = []\n",
        "\n",
        "    print(f\"Starting {n_splits}-Fold Cross Validation...\")\n",
        "    print(f\"Total Epochs per Fold: {TL_EPOCHS} (TL) + {FT_EPOCHS} (FT)\")\n",
        "\n",
        "    # Iterate through folds\n",
        "    for fold, (train_idx, val_idx) in enumerate(\n",
        "        skf.split(full_df, full_df[\"label_index\"])\n",
        "    ):\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"FOLD {fold+1}/{n_splits}\")\n",
        "        print(f\"{'='*40}\")\n",
        "\n",
        "        # --- 1. DATA PREPARATION ---\n",
        "        fold_train_df = full_df.iloc[train_idx].reset_index(drop=True)\n",
        "        fold_val_df = full_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "        # Calculate Class Weights for this specific fold\n",
        "        # (Crucial: Weights change slightly between folds)\n",
        "        fold_class_weights = compute_class_weight(\n",
        "            class_weight=\"balanced\",\n",
        "            classes=np.arange(num_classes),\n",
        "            y=fold_train_df[\"label_index\"].values,\n",
        "        )\n",
        "        fold_weights_tensor = torch.tensor(fold_class_weights, dtype=torch.float).to(\n",
        "            device\n",
        "        )\n",
        "\n",
        "        # Re-initialize Loss with specific fold weights\n",
        "        fold_criterion = FocalLoss(alpha=fold_weights_tensor, gamma=2.0)\n",
        "\n",
        "        # Create Datasets\n",
        "        # Note: We re-instantiate datasets to ensure clean separation\n",
        "        train_ds = MaskedFixedTileDataset(\n",
        "            fold_train_df,\n",
        "            train_set_dir,\n",
        "            transforms=train_transform_tl,\n",
        "            target_size=IMG_RESIZE,\n",
        "            debug_max=None,\n",
        "        )\n",
        "        val_ds = MaskedFixedTileDataset(\n",
        "            fold_val_df,\n",
        "            train_set_dir,\n",
        "            transforms=data_transforms,\n",
        "            target_size=IMG_RESIZE,\n",
        "            debug_max=None,\n",
        "        )\n",
        "\n",
        "        train_loader = make_loader(train_ds, BATCH_SIZE, shuffle=True)\n",
        "        val_loader = make_loader(val_ds, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        # --- 2. PHASE 1: TRANSFER LEARNING (Warm-Up) ---\n",
        "        print(f\"Fold {fold+1} >> Phase 1: Transfer Learning (Frozen Backbone)\")\n",
        "\n",
        "        # Initialize Fresh Model\n",
        "        model = CustomNet(num_classes, TL_DROPOUT_RATE, backbone=NET_NAME).to(device)\n",
        "        model.freeze_backbone()\n",
        "\n",
        "        optimizer_tl = AdamW(\n",
        "            model.parameters(), lr=LEARNING_RATE, weight_decay=TL_WEIGHT_DECAY\n",
        "        )\n",
        "        scaler_tl = torch.amp.GradScaler(enabled=(device.type == \"cuda\")) # type: ignore\n",
        "        scheduler_tl = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer_tl, T_max=TL_EPOCHS, eta_min=1e-6\n",
        "        )\n",
        "\n",
        "        # Run Fit (TL)\n",
        "        tl_model, tl_hystory = fit(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=TL_EPOCHS,\n",
        "            criterion=fold_criterion,\n",
        "            optimizer=optimizer_tl,\n",
        "            scaler=scaler_tl,\n",
        "            device=device,\n",
        "            scheduler=scheduler_tl,\n",
        "            experiment_name=f\"{base_experiment_name}_fold{fold+1}_tl\",\n",
        "            patience=TL_PATIENCE,\n",
        "            mixup_alpha=0.0,\n",
        "            use_swa=False,\n",
        "            verbose=VERBOSE,\n",
        "            writer=writer,\n",
        "            grad_accumulation_steps=GRAD_ACCUMULATION_STEPS,\n",
        "        )\n",
        "\n",
        "        # --- 3. PHASE 2: FINE TUNING (Full Training) ---\n",
        "        print(f\"Fold {fold+1} >> Phase 2: Fine Tuning (Unfrozen + MixUp + SWA)\")\n",
        "\n",
        "        # Unfreeze\n",
        "        tl_model.unfreeze_backbone(N_LAYERS_TO_UNFREEZE, all=False)\n",
        "\n",
        "        total_params = sum(p.numel() for p in tl_model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in tl_model.parameters() if p.requires_grad)\n",
        "\n",
        "        print(f\"Total parameters: {total_params:,}\")\n",
        "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "        print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
        "\n",
        "        # Switch Transforms to Heavy Augmentation\n",
        "        train_ds.transforms = train_transform_ft  # Update dataset transform in-place\n",
        "\n",
        "        # New Optimizer (Lower LR)\n",
        "        optimizer_ft = AdamW(\n",
        "            model.parameters(), lr=FT_LEARNING_RATE, weight_decay=FT_WEIGHT_DECAY\n",
        "        )\n",
        "        scaler_ft = torch.amp.GradScaler(enabled=(device.type == \"cuda\")) # type: ignore\n",
        "        scheduler_ft = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer_ft, T_max=FT_EPOCHS, eta_min=1e-6\n",
        "        )\n",
        "\n",
        "        # Run Fit (FT)\n",
        "        # Note: We use the SWA Start logic here.\n",
        "        # If Epochs=200, start averaging around 150.\n",
        "        swa_start = int(FT_EPOCHS * 0.75)\n",
        "\n",
        "        ft_model, ft_history = fit(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=FT_EPOCHS,\n",
        "            criterion=fold_criterion,\n",
        "            optimizer=optimizer_ft,\n",
        "            scaler=scaler_ft,\n",
        "            device=device,\n",
        "            scheduler=scheduler_ft,\n",
        "            experiment_name=f\"{base_experiment_name}_fold{fold+1}_ft\",\n",
        "            patience=FT_PATIENCE,\n",
        "            mixup_alpha=MIXUP_ALPHA,\n",
        "            use_swa=False,\n",
        "            swa_start_epoch=swa_start,\n",
        "            verbose=VERBOSE,\n",
        "            writer=writer,\n",
        "            grad_accumulation_steps=GRAD_ACCUMULATION_STEPS,\n",
        "        )\n",
        "\n",
        "        best_f1 = max(ft_history[\"val_f1\"])\n",
        "        print(f\"Fold {fold+1} Completed. Best F1: {best_f1:.4f}\")\n",
        "        fold_results.append(best_f1)\n",
        "\n",
        "        analyze_performance(ft_model, val_loader, device, class_names)\n",
        "        plot_history(tl_hystory, ft_history)\n",
        "\n",
        "        # Cleanup to free GPU memory for next fold\n",
        "        del (\n",
        "            tl_model,\n",
        "            ft_model,\n",
        "            optimizer_tl,\n",
        "            optimizer_ft,\n",
        "            scaler_tl,\n",
        "            scaler_ft,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            train_ds,\n",
        "            val_ds,\n",
        "        )\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # --- SUMMARY ---\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(\"CROSS VALIDATION COMPLETE\")\n",
        "    print(f\"Folds: {fold_results}\")\n",
        "    print(f\"Average F1: {np.mean(fold_results):.4f} (+/- {np.std(fold_results):.4f})\")\n",
        "    print(f\"{'='*40}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64a21ea",
      "metadata": {},
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ulntce16E9NJ",
      "metadata": {
        "id": "ulntce16E9NJ"
      },
      "outputs": [],
      "source": [
        "# Setup training\n",
        "\n",
        "writer = SummaryWriter(\"./\" + logs_dir + \"/\" + EXPERIMENT_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967d7d8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "run_k_fold_training(full_df, n_splits=K_FOLD, base_experiment_name=EXPERIMENT_NAME, writer=writer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365f9814",
      "metadata": {
        "id": "365f9814"
      },
      "source": [
        "## **Inference on test data for kaggle**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb67d492",
      "metadata": {},
      "outputs": [],
      "source": [
        "def top_k_mean_aggregation(prob_matrix, k_percent=0.5):\n",
        "    \"\"\"\n",
        "    Aggregates patch probabilities into a slide prediction by averaging\n",
        "    only the most confident patches (Top-K%).\n",
        "\n",
        "    Args:\n",
        "        prob_matrix: Numpy array of shape [N_patches, N_classes]\n",
        "        k_percent: Float (0.0 to 1.0). Percentage of patches to keep.\n",
        "                   0.3 means we only average the top 30% scores.\n",
        "    \"\"\"\n",
        "    n_patches = prob_matrix.shape[0]\n",
        "\n",
        "    # Safety check: if slide has very few patches, keep at least 1\n",
        "    k = max(1, int(n_patches * k_percent))\n",
        "\n",
        "    # Sort probabilities for each class INDEPENDENTLY (Axis 0 = patches)\n",
        "    # We want the highest probabilities for Class 0, Class 1, etc.\n",
        "    sorted_probs = np.sort(prob_matrix, axis=0)\n",
        "\n",
        "    # Take the top K (the last K elements in the sorted array)\n",
        "    top_k_probs = sorted_probs[-k:, :]\n",
        "\n",
        "    # Average them\n",
        "    slide_score = np.mean(top_k_probs, axis=0)\n",
        "\n",
        "    return slide_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9964ad6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9964ad6",
        "outputId": "577dadf8-ba13-4832-a3c0-dde85f0cc914"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import gc\n",
        "\n",
        "\n",
        "def generate_ensemble_submission(\n",
        "    test_dir,\n",
        "    base_experiment_name=\"efficientnet_v2s\",\n",
        "    num_folds=5,\n",
        "    output_file=\"submission_ensemble.csv\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads K models, sums their probabilities, and performs Soft Voting.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Setup Test Dataset & Loader\n",
        "    # We use the dataset once to establish the order of patches\n",
        "    print(f\"Preparing Test Dataset from {test_dir}...\")\n",
        "    test_ds = MaskedFixedTileDataset(\n",
        "        dataframe=None,\n",
        "        img_dir=test_dir,\n",
        "        transforms=data_transforms,\n",
        "        target_size=IMG_RESIZE,\n",
        "        debug_max=None,\n",
        "    )\n",
        "\n",
        "    test_loader = make_loader(test_ds, BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    num_patches = len(test_ds)\n",
        "    print(f\"Total Patches to Process: {num_patches}\")\n",
        "\n",
        "    # matrix to store accumulated probabilities [N_patches, N_classes]\n",
        "    # We initialize with zeros\n",
        "    accumulated_probs = np.zeros((num_patches, num_classes), dtype=np.float32)\n",
        "\n",
        "    # We need to store parent_ids to aggregate later\n",
        "    # The loader is deterministic (shuffle=False), so we can extract them once\n",
        "    all_parent_ids = []\n",
        "\n",
        "    # 2. Iterate through each Fold Model\n",
        "    for fold in range(1, num_folds + 1):\n",
        "        model_path = f\"models/{base_experiment_name}_fold{fold}_ft_model.pt\"\n",
        "        print(f\"\\n--- Loading Model {fold}/{num_folds}: {model_path} ---\")\n",
        "\n",
        "        # Load Model\n",
        "        try:\n",
        "            model = CustomNet(num_classes, FT_DROPOUT_RATE).to(device)\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "            model.eval()\n",
        "        except FileNotFoundError:\n",
        "            print(f\"âš ï¸ Warning: Model file {model_path} not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Inference Loop for this model\n",
        "        fold_patch_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, _, parent_ids in tqdm(\n",
        "                test_loader, desc=f\"Inference Fold {fold}\"\n",
        "            ):\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                # --- TTA Strategy (Same as Validation) ---\n",
        "                # 1. Original\n",
        "                out1 = F.softmax(model(inputs), dim=1)\n",
        "\n",
        "                # 2. Horizontal Flip\n",
        "                inputs_hf = torch.flip(inputs, dims=[3])\n",
        "                out2 = F.softmax(model(inputs_hf), dim=1)\n",
        "\n",
        "                # 3. Vertical Flip\n",
        "                inputs_vf = torch.flip(inputs, dims=[2])\n",
        "                out3 = F.softmax(model(inputs_vf), dim=1)\n",
        "\n",
        "                # Average predictions for this model\n",
        "                avg_probs = (out1 + out2 + out3) / 3.0\n",
        "\n",
        "                # Store\n",
        "                fold_patch_probs.extend(avg_probs.cpu().numpy())\n",
        "\n",
        "                # Only collect parent_ids on the first fold (optimization)\n",
        "                if fold == 1:\n",
        "                    all_parent_ids.extend(parent_ids)\n",
        "\n",
        "        # Add to global accumulator\n",
        "        accumulated_probs += np.array(fold_patch_probs)\n",
        "\n",
        "        # Cleanup\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # 3. Average & Aggregate\n",
        "    print(\"\\nAveraging Ensembled Probabilities...\")\n",
        "    final_avg_probs = accumulated_probs / num_folds\n",
        "\n",
        "    # Now we have [Patch, Probs]. We need [Slide, Probs]\n",
        "    slide_probs = {}\n",
        "\n",
        "    print(\"Aggregating Patches to Slides (Soft Voting)...\")\n",
        "    for i, pid in enumerate(all_parent_ids):\n",
        "        if pid not in slide_probs:\n",
        "            slide_probs[pid] = []\n",
        "        slide_probs[pid].append(final_avg_probs[i])\n",
        "\n",
        "    final_rows = []\n",
        "\n",
        "    for img_name, prob_list in slide_probs.items():\n",
        "        # Stack patches for this slide\n",
        "        prob_matrix = np.array(prob_list)\n",
        "\n",
        "        slide_avg = top_k_mean_aggregation(prob_matrix=prob_matrix, k_percent=0.3)\n",
        "\n",
        "        # Argmax for final label\n",
        "        pred_idx = np.argmax(slide_avg)\n",
        "        pred_label = class_names[pred_idx]\n",
        "\n",
        "        # Filename formatting\n",
        "        sample_index = img_name  # Assuming format matches submission reqs\n",
        "\n",
        "        final_rows.append({\"sample_index\": sample_index, \"label\": pred_label})\n",
        "\n",
        "    # 4. Save Submission\n",
        "    submission_df = pd.DataFrame(final_rows)\n",
        "    submission_df = submission_df.sort_values(by=\"sample_index\")\n",
        "\n",
        "    os.makedirs(\"submission\", exist_ok=True)\n",
        "    submission_path = os.path.join(\"submission\", output_file)\n",
        "    submission_df.to_csv(submission_path, index=False)\n",
        "\n",
        "    print(f\"âœ… Ensemble Submission Saved: {submission_path}\")\n",
        "    return submission_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356d24aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "ensemble_df = generate_ensemble_submission(\n",
        "    test_dir=test_set_dir,\n",
        "    base_experiment_name=EXPERIMENT_NAME,  \n",
        "    num_folds=K_FOLD,\n",
        "    output_file=f\"{EXPERIMENT_NAME}_ensemble_{K_FOLD}fold.csv\",\n",
        ")\n",
        "\n",
        "ensemble_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f6c632",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
