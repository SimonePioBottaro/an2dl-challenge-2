{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Artificial Neural Networks and Deep Learning**\n","\n","---\n","\n","## **Lecture 7: Transfer Learning and Fine-Tuning**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1gsJ4h701PWou3B_JsjbfhIZnefsn2mGN\" width=\"500\"/>"],"metadata":{"id":"6qoJrF0_76_t"}},{"cell_type":"markdown","source":["## üåê **Google Drive Connection**"],"metadata":{"id":"BLUcZWLQ8BiL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxhK7_Ww5sRH"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/gdrive\")\n","current_dir = \"/gdrive/My\\\\ Drive/[2025-2026]\\\\ AN2DL/Lecture\\\\ 7\"\n","%cd $current_dir"]},{"cell_type":"markdown","source":["## ‚öôÔ∏è **Libraries Import**"],"metadata":{"id":"3T9IfEmz8Igc"}},{"cell_type":"code","source":["# Set seed for reproducibility\n","SEED = 42\n","\n","# Import necessary libraries\n","import os\n","\n","# Set environment variables before importing modules\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n","\n","# Suppress warnings\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","# Import necessary modules\n","import logging\n","import random\n","import numpy as np\n","\n","# Set seeds for random number generators in NumPy and Python\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Import PyTorch\n","import torch\n","torch.manual_seed(SEED)\n","from torch import nn\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision\n","from torchvision.transforms import v2 as transforms\n","from torch.utils.data import TensorDataset, DataLoader\n","from torchvision.datasets import OxfordIIITPet\n","from torchvision.transforms import InterpolationMode\n","!pip install torchview\n","from torchview import draw_graph\n","\n","# Configurazione di TensorBoard e directory\n","logs_dir = \"tensorboard\"\n","!pkill -f tensorboard\n","%load_ext tensorboard\n","!mkdir -p models\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.benchmark = True\n","else:\n","    device = torch.device(\"cpu\")\n","\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"Device: {device}\")\n","\n","# Import other libraries\n","import requests\n","from io import BytesIO\n","import cv2\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# Configure plot display settings\n","sns.set(font_scale=1.4)\n","sns.set_style('white')\n","plt.rc('font', size=14)\n","%matplotlib inline"],"metadata":{"id":"NyWck-7y7nAJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ‚è≥ **Data Loading**"],"metadata":{"id":"KUTYqJ2o8MU1"}},{"cell_type":"code","source":["def load_oxford_pets():\n","    \"\"\"\n","    Load Oxford-IIIT Pet dataset, resize to 128x128.\n","    Optimized: Uses batch loading to fill a pre-allocated tensor, avoiding IPC freeze.\n","    \"\"\"\n","    from torchvision.datasets import OxfordIIITPet\n","    from torchvision.transforms import InterpolationMode\n","    import math\n","\n","    # Define transforms: Resize to 128x128, convert to Float Tensor\n","    transform = transforms.Compose([\n","        transforms.ToImage(),\n","        transforms.Resize((128, 128), antialias=True),\n","        transforms.ToDtype(torch.float32, scale=True)\n","    ])\n","\n","    # Initialize datasets\n","    train_dataset = OxfordIIITPet(root='./data', split='trainval', download=True, transform=transform)\n","    test_dataset = OxfordIIITPet(root='./data', split='test', download=True, transform=transform)\n","\n","    # Helper function to load dataset into a pre-allocated tensor\n","    def fill_dataset(dataset, batch_size=512):\n","        n_samples = len(dataset)\n","        # Pre-allocate memory (N, 3, 128, 128)\n","        X = torch.zeros((n_samples, 3, 128, 128), dtype=torch.float32)\n","        y = torch.zeros(n_samples, dtype=torch.int64)\n","\n","        # Use multiple workers for parallel resizing\n","        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n","                            num_workers=os.cpu_count() or 2)\n","\n","        print(f\"Loading {n_samples} images with {loader.num_workers} workers...\")\n","\n","        start_idx = 0\n","        for batch_x, batch_y in loader:\n","            end_idx = start_idx + batch_x.shape[0]\n","            X[start_idx:end_idx] = batch_x\n","            y[start_idx:end_idx] = batch_y\n","            start_idx = end_idx\n","\n","        return X, y\n","\n","    # Load training data\n","    print(\"Processing Training Data...\")\n","    X_train_tensor, y_train_tensor = fill_dataset(train_dataset)\n","\n","    # Load test data\n","    print(\"Processing Test Data...\")\n","    X_test_tensor, y_test_tensor = fill_dataset(test_dataset)\n","\n","    # Get class names\n","    class_names = [name.lower() for name in train_dataset.classes]\n","\n","    # Convert to NumPy (fast operation on CPU tensors)\n","    return (X_train_tensor.numpy(), y_train_tensor.numpy()), \\\n","           (X_test_tensor.numpy(), y_test_tensor.numpy()), \\\n","           class_names\n","\n","# Execute loading\n","(X_train, y_train), (X_test, y_test), class_names = load_oxford_pets()\n","\n","# Display shapes\n","print(\"\\nTraining set shape:\", X_train.shape)\n","print(\"Test set shape:\", X_test.shape)\n","print(f\"Number of classes: {len(class_names)}\")"],"metadata":{"id":"Fa5YtYC572sa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîé **Data Exploration**"],"metadata":{"id":"FfwDyTmQ8Y1v"}},{"cell_type":"code","source":["# Number of images to display\n","num_img = 10\n","\n","# Select random indices from the training set\n","random_indices = random.sample(range(len(X_train)), num_img)\n","\n","# Create subplot layout for images\n","fig, axes = plt.subplots(2, num_img // 2, figsize=(20, 9))\n","\n","for i, idx in enumerate(random_indices):\n","    ax = axes[i // 5, i % 5]\n","\n","    # Display the image at the selected index (convert CHW to HWC)\n","    img = X_train[idx].transpose(1, 2, 0)\n","    ax.imshow(img)\n","\n","    # Add class name as title\n","    class_name = class_names[y_train[idx]]\n","    class_name = class_name.replace('_', ' ').title()\n","    ax.set_title(class_name, pad=5)\n","\n","    # Remove axis lines for clearer display\n","    ax.axis('off')\n","\n","# Adjust layout for better spacing\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"S9XZJPy_9UGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_class_distribution(y_train, y_test, class_names):\n","    \"\"\"Plot class distribution for training and test sets.\"\"\"\n","    sns.set_style(\"whitegrid\")\n","    plt.figure(figsize=(18, 6))\n","\n","    # Calculate class distributions for training and test sets\n","    train_dist = np.bincount(y_train)\n","    test_dist = np.bincount(y_test)\n","\n","    # Create x positions and set bar width\n","    x = np.arange(len(class_names))\n","    width = 0.35\n","\n","    # Plot bars for training and test distributions\n","    plt.bar(x - width / 2, train_dist, width, label='Training', color='#1f77b4', alpha=0.7)\n","    plt.bar(x + width / 2, test_dist, width, label='Test', color='#ff7f0e', alpha=0.7)\n","\n","    # Customize plot title and labels\n","    plt.title('Class Distribution', pad=20, fontsize=14)\n","    plt.xlabel('Classes')\n","    plt.ylabel('Number of Images')\n","\n","    # Set class names as x-axis labels with rotation\n","    plt.xticks(x, class_names, rotation=45, ha='right')\n","\n","    # Add legend for training and test distributions\n","    plt.legend(loc='lower right')\n","\n","    # Adjust layout for optimal spacing\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Execute function to plot class distribution\n","plot_class_distribution(y_train, y_test, class_names)"],"metadata":{"id":"qBQSKIcw9Vg9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  üìÑ **Data Preprocessing**"],"metadata":{"id":"d2QVndE59YRN"}},{"cell_type":"code","source":["# Split test set into validation and test sets with stratification\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_test, y_test, random_state=SEED, test_size=0.5, stratify=y_test\n",")\n","\n","# Print shapes of the datasets\n","print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n","print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"],"metadata":{"id":"PwEZrEUi9Y-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the input shape and number of classes\n","input_shape = (3, 128, 128)\n","num_classes = len(class_names)\n","\n","print(\"Input Shape:\", input_shape)\n","print(\"Number of Classes:\", num_classes)"],"metadata":{"id":"7N52vSnY9aGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the batch size\n","BATCH_SIZE = 64"],"metadata":{"id":"9zpjtsYT9bB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ImageNet normalization statistics\n","IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD = [0.229, 0.224, 0.225]\n","\n","\n","class PetsDataset(torch.utils.data.Dataset):\n","    \"\"\"Custom PyTorch Dataset for Oxford Pets with optional augmentation and normalization.\"\"\"\n","\n","    def __init__(self, data, labels, augmentation=None, normalize_imagenet=False):\n","        \"\"\"\n","        Args:\n","            data: numpy array of images (N, C, H, W) in range [0, 1]\n","            labels: numpy array of labels\n","            augmentation: transforms for data augmentation\n","            normalize_imagenet: whether to apply ImageNet normalization\n","        \"\"\"\n","        self.data = torch.from_numpy(data)\n","        self.labels = torch.from_numpy(labels).long()\n","        self.augmentation = augmentation\n","        self.normalize_imagenet = normalize_imagenet\n","\n","        # ImageNet normalization transform\n","        if normalize_imagenet:\n","            self.normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n","        else:\n","            self.normalize = None\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image = self.data[idx].clone()  # Clone to avoid modifying original\n","        label = self.labels[idx]\n","\n","        # Apply augmentation if provided (on images in [0, 1] range)\n","        if self.augmentation:\n","            image = self.augmentation(image)\n","\n","        # Apply ImageNet normalization if requested\n","        if self.normalize:\n","            image = self.normalize(image)\n","\n","        return image, label"],"metadata":{"id":"JqUEgGir9c4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_loader(ds, batch_size, shuffle, drop_last):\n","    \"\"\"Create a PyTorch DataLoader with optimized settings.\"\"\"\n","    cpu_cores = os.cpu_count() or 2\n","    num_workers = max(2, min(4, cpu_cores))\n","\n","    return DataLoader(\n","        ds,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=drop_last,\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n","        prefetch_factor=4,\n","    )"],"metadata":{"id":"SHzx4NqM9eWV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  üßÆ **Network Parameters**"],"metadata":{"id":"Eb9DVpuR9gBd"}},{"cell_type":"code","source":["# Training parameters\n","LEARNING_RATE = 1e-3\n","EPOCHS = 200\n","PATIENCE = 20\n","\n","# Regularization\n","DROPOUT_RATE = 0.3\n","\n","# Set up loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Print the defined parameters\n","print(\"Epochs:\", EPOCHS)\n","print(\"Batch Size:\", BATCH_SIZE)\n","print(\"Learning Rate:\", LEARNING_RATE)\n","print(\"Dropout Rate:\", DROPOUT_RATE)\n","print(\"Patience:\", PATIENCE)"],"metadata":{"id":"Bw65OSaz9fre"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  üß† **Training Functions**"],"metadata":{"id":"6jpoBYs_9ihm"}},{"cell_type":"code","source":["def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device):\n","    \"\"\"Train for one epoch.\"\"\"\n","    model.train()\n","\n","    running_loss = 0.0\n","    all_predictions = []\n","    all_targets = []\n","\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad(set_to_none=True)\n","\n","        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n","            logits = model(inputs)\n","            loss = criterion(logits, targets)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        predictions = logits.argmax(dim=1)\n","        all_predictions.append(predictions.cpu().numpy())\n","        all_targets.append(targets.cpu().numpy())\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = accuracy_score(\n","        np.concatenate(all_targets),\n","        np.concatenate(all_predictions)\n","    )\n","\n","    return epoch_loss, epoch_acc\n","\n","\n","def validate_one_epoch(model, val_loader, criterion, device):\n","    \"\"\"Validate for one epoch.\"\"\"\n","    model.eval()\n","\n","    running_loss = 0.0\n","    all_predictions = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n","                logits = model(inputs)\n","                loss = criterion(logits, targets)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            predictions = logits.argmax(dim=1)\n","            all_predictions.append(predictions.cpu().numpy())\n","            all_targets.append(targets.cpu().numpy())\n","\n","    epoch_loss = running_loss / len(val_loader.dataset)\n","    epoch_accuracy = accuracy_score(\n","        np.concatenate(all_targets),\n","        np.concatenate(all_predictions)\n","    )\n","\n","    return epoch_loss, epoch_accuracy\n","\n","\n","def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n","        patience=0, evaluation_metric=\"val_acc\", mode='max',\n","        restore_best_weights=True, writer=None, verbose=1, experiment_name=\"\"):\n","    \"\"\"Train the neural network model.\"\"\"\n","\n","    training_history = {\n","        'train_loss': [], 'val_loss': [],\n","        'train_acc': [], 'val_acc': []\n","    }\n","\n","    if patience > 0:\n","        patience_counter = 0\n","        best_metric = float('-inf') if mode == 'max' else float('inf')\n","        best_epoch = 0\n","\n","    print(f\"Training {epochs} epochs...\")\n","\n","    for epoch in range(1, epochs + 1):\n","        train_loss, train_acc = train_one_epoch(\n","            model, train_loader, criterion, optimizer, scaler, device\n","        )\n","\n","        val_loss, val_acc = validate_one_epoch(\n","            model, val_loader, criterion, device\n","        )\n","\n","        training_history['train_loss'].append(train_loss)\n","        training_history['val_loss'].append(val_loss)\n","        training_history['train_acc'].append(train_acc)\n","        training_history['val_acc'].append(val_acc)\n","\n","        if writer is not None:\n","            writer.add_scalar('Loss/Training', train_loss, epoch)\n","            writer.add_scalar('Loss/Validation', val_loss, epoch)\n","            writer.add_scalar('Accuracy/Training', train_acc, epoch)\n","            writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n","\n","        if verbose > 0:\n","            if epoch % verbose == 0 or epoch == 1:\n","                print(f\"Epoch {epoch:3d}/{epochs} | \"\n","                    f\"Train: Loss={train_loss:.4f}, Acc={train_acc:.4f} | \"\n","                    f\"Val: Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n","\n","        if patience > 0:\n","            current_metric = training_history[evaluation_metric][-1]\n","            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n","\n","            if is_improvement:\n","                best_metric = current_metric\n","                best_epoch = epoch\n","                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter >= patience:\n","                    print(f\"Early stopping triggered after {epoch} epochs.\")\n","                    break\n","\n","    if restore_best_weights and patience > 0:\n","        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n","        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n","\n","    if patience == 0:\n","        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n","\n","    if writer is not None:\n","        writer.close()\n","\n","    return model, training_history"],"metadata":{"id":"ltDGkrbv9hAt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  üõ†Ô∏è **Train EfficientNetB0 from Scratch**"],"metadata":{"id":"q-T4ohd29lpu"}},{"cell_type":"code","source":["class EfficientNetB0FromScratch(nn.Module):\n","    \"\"\"EfficientNet-B0 trained from scratch (Random weights).\"\"\"\n","\n","    def __init__(self, num_classes, dropout_rate=0.3):\n","        super().__init__()\n","\n","        # Load architecture with NO pretrained weights\n","        self.backbone = torchvision.models.efficientnet_b0(weights=None)\n","\n","        # Re-build classifier head\n","        # EfficientNet classifier is a Sequential; the Linear layer is the last one [-1]\n","        in_features = self.backbone.classifier[-1].in_features\n","\n","        self.backbone.classifier = nn.Sequential(\n","            nn.Dropout(p=dropout_rate, inplace=True),\n","            nn.Linear(in_features, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        return self.backbone(x)"],"metadata":{"id":"wyu6j5o79mgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize model\n","scratch_model = EfficientNetB0FromScratch(num_classes, DROPOUT_RATE).to(device)\n","\n","# Visualize structure\n","summary(scratch_model, input_size=input_shape)\n","model_graph = draw_graph(scratch_model, input_size=(BATCH_SIZE,)+input_shape, expand_nested=True, depth=6)\n","model_graph.visual_graph"],"metadata":{"id":"rgQCIs9W9ntu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define augmentation for training\n","train_augmentation = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n","    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2))\n","])\n","\n","# Create datasets WITHOUT ImageNet normalization (training from scratch)\n","train_scratch_ds = PetsDataset(X_train, y_train, augmentation=train_augmentation, normalize_imagenet=True)\n","val_scratch_ds = PetsDataset(X_val, y_val, augmentation=None, normalize_imagenet=True)\n","\n","train_scratch_loader = make_loader(train_scratch_ds, BATCH_SIZE, shuffle=True, drop_last=False)\n","val_scratch_loader = make_loader(val_scratch_ds, BATCH_SIZE, shuffle=False, drop_last=False)"],"metadata":{"id":"lPAdE1QV9on2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup Training\n","experiment_name = \"from_scratch\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","optimizer = torch.optim.Adam(scratch_model.parameters(), lr=LEARNING_RATE)\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"],"metadata":{"id":"yHMcD6eX9p3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Train model from scratch\n","scratch_model, scratch_history = fit(\n","    model=scratch_model,\n","    train_loader=train_scratch_loader,\n","    val_loader=val_scratch_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=5,\n","    experiment_name=experiment_name,\n","    patience=PATIENCE\n",")\n","\n","final_val_acc = round(max(scratch_history['val_acc']) * 100, 2)\n","print(f'Final validation accuracy: {final_val_acc}%')"],"metadata":{"id":"a25y1qzp9rQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Plot History\n","# Create a figure with two side-by-side subplots\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(scratch_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(scratch_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Categorical Crossentropy')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation Accuracy on the second axis\n","ax2.plot(scratch_history['train_acc'], label='Training Accuracy', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(scratch_history['val_acc'], label='Validation Accuracy', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('Accuracy')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"],"metadata":{"cellView":"form","id":"KUk0P559QVmk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üõ†Ô∏è **Transfer Learning**"],"metadata":{"id":"RwbwuwW0APdp"}},{"cell_type":"code","source":["class EfficientNetB0TransferLearning(nn.Module):\n","    \"\"\"EfficientNet-B0 with ImageNet pretrained weights.\"\"\"\n","\n","    def __init__(self, num_classes, dropout_rate=0.3, freeze_backbone=True):\n","        super().__init__()\n","\n","        # Load weights pretrained on ImageNet\n","        self.backbone = torchvision.models.efficientnet_b0(\n","            weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n","        )\n","\n","        # Freeze the backbone layers (features)\n","        if freeze_backbone:\n","            for param in self.backbone.features.parameters():\n","                param.requires_grad = False\n","\n","        # Replace classifier (Always trainable)\n","        in_features = self.backbone.classifier[-1].in_features\n","        self.backbone.classifier = nn.Sequential(\n","            nn.Dropout(p=dropout_rate, inplace=True),\n","            nn.Linear(in_features, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        return self.backbone(x)"],"metadata":{"id":"4HpgidjSAQI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create transfer learning model\n","tl_model = EfficientNetB0TransferLearning(num_classes, DROPOUT_RATE, freeze_backbone=True).to(device)\n","\n","# Display model summary\n","summary(tl_model, input_size=input_shape)\n","model_graph = draw_graph(tl_model, input_size=(BATCH_SIZE,)+input_shape, expand_nested=True, depth=6)\n","model_graph.visual_graph"],"metadata":{"id":"XjG5EIPGAQdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create datasets WITH ImageNet normalization (for pretrained model)\n","train_tl_ds = PetsDataset(X_train, y_train, augmentation=train_augmentation, normalize_imagenet=True)\n","val_tl_ds = PetsDataset(X_val, y_val, augmentation=None, normalize_imagenet=True)\n","\n","train_tl_loader = make_loader(train_tl_ds, BATCH_SIZE, shuffle=True, drop_last=False)\n","val_tl_loader = make_loader(val_tl_ds, BATCH_SIZE, shuffle=False, drop_last=False)"],"metadata":{"id":"Q0vy9m_SAaAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup training\n","experiment_name = \"transfer_learning\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","optimizer = torch.optim.Adam(tl_model.parameters(), lr=LEARNING_RATE)\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"],"metadata":{"id":"xmfp8dx3Ae8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Train with transfer learning\n","tl_model, tl_history = fit(\n","    model=tl_model,\n","    train_loader=train_tl_loader,\n","    val_loader=val_tl_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=5,\n","    experiment_name=experiment_name,\n","    patience=PATIENCE\n",")\n","\n","final_val_acc = round(max(tl_history['val_acc']) * 100, 2)\n","print(f'Final validation accuracy: {final_val_acc}%')"],"metadata":{"id":"rrfHXSIsAhET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Plot History\n","# Create a figure with two side-by-side subplots\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(tl_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(tl_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Categorical Crossentropy')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation Accuracy on the second axis\n","ax2.plot(tl_history['train_acc'], label='Training Accuracy', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(tl_history['val_acc'], label='Validation Accuracy', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('Accuracy')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"],"metadata":{"id":"Tu7uR6FbAjgb","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üõ†Ô∏è **Fine-Tuning**"],"metadata":{"id":"q7xCkiD9HOcq"}},{"cell_type":"code","source":["# Load the transfer learning model\n","ft_model = EfficientNetB0TransferLearning(num_classes, DROPOUT_RATE, freeze_backbone=False).to(device)\n","ft_model.load_state_dict(torch.load(\"models/transfer_learning_model.pt\"))\n","\n","# Unfreeze the last N layers of the backbone\n","N_LAYERS_TO_UNFREEZE = 20\n","\n","# Strategy: Freeze everything first, then unfreeze the last few blocks\n","for param in ft_model.parameters():\n","    param.requires_grad = False\n","\n","# The classifier is always trainable\n","for param in ft_model.backbone.classifier.parameters():\n","    param.requires_grad = True\n","\n","# Unfreeze the last 2 blocks of the feature extractor (EfficientNet-B0 has 9 blocks usually)\n","# Adjust slice index [-2:] to unfreeze more or fewer layers\n","for block in ft_model.backbone.features[-2:]:\n","    for param in block.parameters():\n","        param.requires_grad = True\n","\n","# Check trainable parameters\n","trainable_params = sum(p.numel() for p in ft_model.parameters() if p.requires_grad)\n","total_params = sum(p.numel() for p in ft_model.parameters())\n","print(f\"Trainable parameters: {trainable_params:,} / {total_params:,}\")"],"metadata":{"id":"VkC2PbRkHPxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reuse datasets from transfer learning (with ImageNet normalization)\n","train_ft_ds = PetsDataset(X_train, y_train, augmentation=train_augmentation, normalize_imagenet=True)\n","val_ft_ds = PetsDataset(X_val, y_val, augmentation=None, normalize_imagenet=True)\n","\n","train_ft_loader = make_loader(train_ft_ds, BATCH_SIZE, shuffle=True, drop_last=False)\n","val_ft_loader = make_loader(val_ft_ds, BATCH_SIZE, shuffle=False, drop_last=False)"],"metadata":{"id":"EDQ-peFoHQ86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup Training (Lower learning rate for Fine-Tuning)\n","experiment_name = \"fine_tuning\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","optimizer = torch.optim.Adam(ft_model.parameters(), lr=1e-4) # 10x smaller LR\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"],"metadata":{"id":"WJ-MILTzHjRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Fine-tune the model\n","ft_model, ft_history = fit(\n","    model=ft_model,\n","    train_loader=train_ft_loader,\n","    val_loader=val_ft_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=5,\n","    experiment_name=experiment_name,\n","    patience=PATIENCE\n",")\n","\n","final_val_acc = round(max(ft_history['val_acc']) * 100, 2)\n","print(f'Final validation accuracy: {final_val_acc}%')"],"metadata":{"id":"U1csxxFUHkXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Plot History\n","# Create a figure with two side-by-side subplots\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(ft_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(ft_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Categorical Crossentropy')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation Accuracy on the second axis\n","ax2.plot(ft_history['train_acc'], label='Training Accuracy', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(ft_history['val_acc'], label='Validation Accuracy', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('Accuracy')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"],"metadata":{"id":"2hsXAbViHl_V","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Copy TensorBoard logs to accessible location for Colab\n","!rsync -a $current_dir\"/\"$logs_dir/ \"/content/\"$logs_dir/\n","\n","# Launch TensorBoard interface\n","%tensorboard --logdir \"/content/\"$logs_dir"],"metadata":{"id":"So4xCgLYREl2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üïπÔ∏è **Use the Model - Make Inference**"],"metadata":{"id":"-IUXiruoRRPA"}},{"cell_type":"code","source":["# Load the fine-tuned model for inference\n","best_model = EfficientNetB0TransferLearning(num_classes, DROPOUT_RATE, freeze_backbone=False).to(device)\n","best_model.load_state_dict(torch.load(\"models/fine_tuning_model.pt\"))\n","best_model.eval()\n","\n","print(\"Model loaded successfully!\")"],"metadata":{"id":"FbvOID7uRRkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_square_center(image):\n","    \"\"\"Crop image to a square, centered on the middle section.\"\"\"\n","    h, w = image.shape[:2]\n","    crop_size = min(h, w)\n","\n","    h_offset = (h - crop_size) // 2\n","    w_offset = (w - crop_size) // 2\n","\n","    return image[h_offset:h_offset + crop_size, w_offset:w_offset + crop_size]\n","\n","\n","def preprocess_for_model(image):\n","    \"\"\"Preprocess image for model input WITH ImageNet normalization.\"\"\"\n","    # Convert to PIL\n","    image_pil = Image.fromarray((image * 255).astype(np.uint8))\n","\n","    # Apply transforms with ImageNet normalization\n","    transform = transforms.Compose([\n","        transforms.ToImage(),\n","        transforms.Resize((128, 128), antialias=True),\n","        transforms.ToDtype(torch.float32, scale=True),\n","        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)  # IMPORTANT!\n","    ])\n","\n","    return transform(image_pil)"],"metadata":{"id":"cLzvQmktRS1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dictionary of image URLs and their actual classes\n","images = {\n","    'pug': 'https://blog.expodog.com/wp-content/uploads/2020/09/f896a647cfc5346c5b042a6a1e916065.jpg',\n","    'persian': 'https://images.squarespace-cdn.com/content/v1/5b1cc0f95b409bd4bfc3b316/1687322332437-DOVUPJBJMKQWZ2TRSQA2/sergey-semin-I9cHfDYLT3E-unsplash%281%29.jpg',\n","    'sphynx': 'https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcpzLYLRORZQaVRNizLejwVBFp8eIUPS_ZN7Zhw_J54RgeELoupne4wHwxj8o8vr6XXlFtJwTj8QGP7VIpbj_UwTU6bp4Z6lIIM80zkyhKBtN8YHeFQQScopDh0nw8loMvhmxvaurUuP8/s1600/Sphynx_associazione_mammagatta-7.jpg',\n","    'abyssinian': 'https://cdn.creatures.com/881/88b/da9/0426b.jpeg',\n","    'samoyed': 'https://images.ctfassets.net/440y9b545yd9/49v1AZmZdiPYkJ4A3vrayj/d7d7db21fed2ef30f5b8e3899633d292/Samoyed850.jpg'\n","}\n","\n","# Create a plot for visualizing model predictions\n","plt.figure(figsize=(25, 5))\n","\n","with torch.no_grad():\n","    for i, (true_class, url) in enumerate(images.items(), 1):\n","        # Load the image from the URL\n","        response = requests.get(url)\n","        img_original = np.array(Image.open(BytesIO(response.content))) / 255\n","\n","        # Crop the image to a square for consistent processing\n","        img_square = crop_square_center(img_original)\n","\n","        # Preprocess image for model prediction (with ImageNet normalization)\n","        img_tensor = preprocess_for_model(img_square).unsqueeze(0).to(device)\n","\n","        # Predict class\n","        output = best_model(img_tensor)\n","        probabilities = torch.softmax(output, dim=1)\n","        pred_idx = probabilities.argmax(dim=1).item()\n","        pred_class = class_names[pred_idx]\n","        confidence = round(100 * probabilities[0, pred_idx].item(), 2)\n","\n","        # Plot the cropped square image\n","        plt.subplot(1, 5, i)\n","        plt.imshow(img_square)\n","        plt.axis('off')\n","\n","        # Add title with actual and predicted class info\n","        plt.title(f'Real: {true_class}\\nPred: {pred_class}\\nConf: {confidence}%',\n","                 fontsize=14, pad=10)\n","\n","# Adjust layout to prevent overlap and display\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"PXl_KyNDRUCw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4tWF6oUQFqH"},"source":["#  \n","<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n","\n","##### Connect with us:\n","- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"14\"> **LinkedIn:**  [AIRLab Polimi](https://www.linkedin.com/company/airlab-polimi/)\n","- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"14\"> **Instagram:** [airlab_polimi](https://www.instagram.com/airlab_polimi/)\n","\n","##### Contributors:\n","- **Eugenio Lomurno**: eugenio.lomurno@polimi.it\n","- **Alberto Archetti**: alberto.archetti@polimi.it\n","- **Roberto Basla**: roberto.basla@polimi.it\n","- **Carlo Sgaravatti**: carlo.sgaravatti@polimi.it\n","\n","```\n","   Copyright 2025 Eugenio Lomurno, Alberto Archetti, Roberto Basla, Carlo Sgaravatti\n","\n","   Licensed under the Apache License, Version 2.0 (the \"License\");\n","   you may not use this file except in compliance with the License.\n","   You may obtain a copy of the License at\n","\n","       http://www.apache.org/licenses/LICENSE-2.0\n","\n","   Unless required by applicable law or agreed to in writing, software\n","   distributed under the License is distributed on an \"AS IS\" BASIS,\n","   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","   See the License for the specific language governing permissions and\n","   limitations under the License.\n","```"]}]}